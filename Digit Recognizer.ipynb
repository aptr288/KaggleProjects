{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praka\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\praka\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train = pd.read_csv('DigitRecogtrain.csv')\n",
    "labels = train.ix[:,0].values.astype('int32')\n",
    "X_train = (train.ix[:,1:].values).astype('float32')\n",
    "X_test = (pd.read_csv('DigitRecogtest.csv').values).astype('float32')\n",
    "# convert list of labels to binary class matrix\n",
    "y_train = np_utils.to_categorical(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing: divide by max and substract mean\n",
    "scale = np.max(X_train)\n",
    "X_train /= scale\n",
    "X_test /= scale\n",
    "\n",
    "mean = np.std(X_train)\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "nb_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a Deep Dumb MLP (DDMLP)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_dim))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praka\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 0.2013 - val_loss: 0.2434\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2014 - val_loss: 0.2381\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.2159 - val_loss: 0.2130\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.2209 - val_loss: 0.2343\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.2145 - val_loss: 0.2495\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.2144 - val_loss: 0.2199\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.2115 - val_loss: 0.2568\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.2274 - val_loss: 0.2571\n",
      "Epoch 9/100\n",
      " - 6s - loss: 0.2253 - val_loss: 0.2723\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.2238 - val_loss: 0.2504\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.2315 - val_loss: 0.2581\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.2267 - val_loss: 0.3106\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.2234 - val_loss: 0.2596\n",
      "Epoch 14/100\n",
      " - 5s - loss: 0.2399 - val_loss: 0.2915\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.2364 - val_loss: 0.3059\n",
      "Epoch 16/100\n",
      " - 5s - loss: 0.2400 - val_loss: 0.2929\n",
      "Epoch 17/100\n",
      " - 5s - loss: 0.2343 - val_loss: 0.2737\n",
      "Epoch 18/100\n",
      " - 5s - loss: 0.2314 - val_loss: 0.2483\n",
      "Epoch 19/100\n",
      " - 5s - loss: 0.2467 - val_loss: 0.2944\n",
      "Epoch 20/100\n",
      " - 6s - loss: 0.2338 - val_loss: 0.3059\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.2305 - val_loss: 0.3226\n",
      "Epoch 22/100\n",
      " - 6s - loss: 0.2369 - val_loss: 0.3018\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.2308 - val_loss: 0.2750\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.2339 - val_loss: 0.2747\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.2198 - val_loss: 0.2832\n",
      "Epoch 26/100\n",
      " - 7s - loss: 0.2355 - val_loss: 0.3440\n",
      "Epoch 27/100\n",
      " - 6s - loss: 0.2421 - val_loss: 0.3195\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.2177 - val_loss: 0.2557\n",
      "Epoch 29/100\n",
      " - 6s - loss: 0.2373 - val_loss: 0.3509\n",
      "Epoch 30/100\n",
      " - 6s - loss: 0.2245 - val_loss: 0.2971\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.2186 - val_loss: 0.2891\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.2266 - val_loss: 0.2983\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.2414 - val_loss: 0.3077\n",
      "Epoch 34/100\n",
      " - 6s - loss: 0.2384 - val_loss: 0.3307\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.2263 - val_loss: 0.3224\n",
      "Epoch 36/100\n",
      " - 6s - loss: 0.2416 - val_loss: 0.3552\n",
      "Epoch 37/100\n",
      " - 6s - loss: 0.2344 - val_loss: 0.3545\n",
      "Epoch 38/100\n",
      " - 6s - loss: 0.2232 - val_loss: 0.2996\n",
      "Epoch 39/100\n",
      " - 6s - loss: 0.2338 - val_loss: 0.3769\n",
      "Epoch 40/100\n",
      " - 6s - loss: 0.2259 - val_loss: 0.3351\n",
      "Epoch 41/100\n",
      " - 5s - loss: 0.2346 - val_loss: 0.3317\n",
      "Epoch 42/100\n",
      " - 6s - loss: 0.2299 - val_loss: 0.3469\n",
      "Epoch 43/100\n",
      " - 6s - loss: 0.2421 - val_loss: 0.3417\n",
      "Epoch 44/100\n",
      " - 5s - loss: 0.2364 - val_loss: 0.3509\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.2220 - val_loss: 0.3149\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.2409 - val_loss: 0.3466\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.2404 - val_loss: 0.3596\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.2265 - val_loss: 0.3482\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.2287 - val_loss: 0.3236\n",
      "Epoch 50/100\n",
      " - 5s - loss: 0.2174 - val_loss: 0.3303\n",
      "Epoch 51/100\n",
      " - 6s - loss: 0.2422 - val_loss: 0.3143\n",
      "Epoch 52/100\n",
      " - 5s - loss: 0.2394 - val_loss: 0.3015\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.2161 - val_loss: 0.3618\n",
      "Epoch 54/100\n",
      " - 5s - loss: 0.2217 - val_loss: 0.3378\n",
      "Epoch 55/100\n",
      " - 5s - loss: 0.2135 - val_loss: 0.3749\n",
      "Epoch 56/100\n",
      " - 5s - loss: 0.2360 - val_loss: 0.3837\n",
      "Epoch 57/100\n",
      " - 5s - loss: 0.2320 - val_loss: 0.3377\n",
      "Epoch 58/100\n",
      " - 5s - loss: 0.2224 - val_loss: 0.3253\n",
      "Epoch 59/100\n",
      " - 5s - loss: 0.2215 - val_loss: 0.2726\n",
      "Epoch 60/100\n",
      " - 5s - loss: 0.2154 - val_loss: 0.3124\n",
      "Epoch 61/100\n",
      " - 6s - loss: 0.2388 - val_loss: 0.3176\n",
      "Epoch 62/100\n",
      " - 6s - loss: 0.2437 - val_loss: 0.4031\n",
      "Epoch 63/100\n",
      " - 6s - loss: 0.2321 - val_loss: 0.3538\n",
      "Epoch 64/100\n",
      " - 5s - loss: 0.2218 - val_loss: 0.3502\n",
      "Epoch 65/100\n",
      " - 5s - loss: 0.2246 - val_loss: 0.3523\n",
      "Epoch 66/100\n",
      " - 5s - loss: 0.2304 - val_loss: 0.3736\n",
      "Epoch 67/100\n",
      " - 5s - loss: 0.2196 - val_loss: 0.3612\n",
      "Epoch 68/100\n",
      " - 5s - loss: 0.2141 - val_loss: 0.4177\n",
      "Epoch 69/100\n",
      " - 5s - loss: 0.2192 - val_loss: 0.3522\n",
      "Epoch 70/100\n",
      " - 5s - loss: 0.2283 - val_loss: 0.3564\n",
      "Epoch 71/100\n",
      " - 5s - loss: 0.2225 - val_loss: 0.3743\n",
      "Epoch 72/100\n",
      " - 5s - loss: 0.2218 - val_loss: 0.3325\n",
      "Epoch 73/100\n",
      " - 5s - loss: 0.2407 - val_loss: 0.4316\n",
      "Epoch 74/100\n",
      " - 6s - loss: 0.2128 - val_loss: 0.3992\n",
      "Epoch 75/100\n",
      " - 7s - loss: 0.2133 - val_loss: 0.3870\n",
      "Epoch 76/100\n",
      " - 5s - loss: 0.2252 - val_loss: 0.3528\n",
      "Epoch 77/100\n",
      " - 5s - loss: 0.2264 - val_loss: 0.4384\n",
      "Epoch 78/100\n",
      " - 5s - loss: 0.2151 - val_loss: 0.3913\n",
      "Epoch 79/100\n",
      " - 5s - loss: 0.2107 - val_loss: 0.4100\n",
      "Epoch 80/100\n",
      " - 5s - loss: 0.2148 - val_loss: 0.3682\n",
      "Epoch 81/100\n",
      " - 5s - loss: 0.2028 - val_loss: 0.3343\n",
      "Epoch 82/100\n",
      " - 5s - loss: 0.2162 - val_loss: 0.3279\n",
      "Epoch 83/100\n",
      " - 5s - loss: 0.2091 - val_loss: 0.3282\n",
      "Epoch 84/100\n",
      " - 6s - loss: 0.2071 - val_loss: 0.3877\n",
      "Epoch 85/100\n",
      " - 5s - loss: 0.2191 - val_loss: 0.3802\n",
      "Epoch 86/100\n",
      " - 5s - loss: 0.2095 - val_loss: 0.3845\n",
      "Epoch 87/100\n",
      " - 5s - loss: 0.2295 - val_loss: 0.3681\n",
      "Epoch 88/100\n",
      " - 5s - loss: 0.2143 - val_loss: 0.3600\n",
      "Epoch 89/100\n",
      " - 5s - loss: 0.2101 - val_loss: 0.3449\n",
      "Epoch 90/100\n",
      " - 5s - loss: 0.2198 - val_loss: 0.3878\n",
      "Epoch 91/100\n",
      " - 5s - loss: 0.2045 - val_loss: 0.3619\n",
      "Epoch 92/100\n",
      " - 5s - loss: 0.2001 - val_loss: 0.3756\n",
      "Epoch 93/100\n",
      " - 5s - loss: 0.2228 - val_loss: 0.3836\n",
      "Epoch 94/100\n",
      " - 5s - loss: 0.2247 - val_loss: 0.4398\n",
      "Epoch 95/100\n",
      " - 5s - loss: 0.2059 - val_loss: 0.4040\n",
      "Epoch 96/100\n",
      " - 5s - loss: 0.2153 - val_loss: 0.3358\n",
      "Epoch 97/100\n",
      " - 5s - loss: 0.2080 - val_loss: 0.3228\n",
      "Epoch 98/100\n",
      " - 5s - loss: 0.2142 - val_loss: 0.3594\n",
      "Epoch 99/100\n",
      " - 5s - loss: 0.2081 - val_loss: 0.3291\n",
      "Epoch 100/100\n",
      " - 5s - loss: 0.2068 - val_loss: 0.3823\n",
      "Generating test predictions...\n"
     ]
    }
   ],
   "source": [
    "# we'll use categorical xent for the loss, and RMSprop as the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, y_train, nb_epoch=100, batch_size=16, validation_split=0.1, verbose=2)\n",
    "\n",
    "print(\"Generating test predictions...\")\n",
    "preds = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "def write_preds(preds, fname):\n",
    "    pd.DataFrame({\"ImageId\": list(range(1,len(preds)+1)), \"Label\": preds}).to_csv(fname, index=False, header=True)\n",
    "\n",
    "write_preds(preds, \"keras-mlp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
