# KaggleProjects

* **Titanic: Machine Learning from Disaster competition** - Developed model which ranked Top 6% Where in employed feature engineering to better expose data and parameter tuning.  
*	**Digit Recognizer** - Implemented basic neural network on MNIST data with 97% accuracy.
*	**Microsoft Malware Prediction** â€“ Employed Dask to deal with huge dataset (8 million rows) using parallel processing and various imputations to handle missing values. Used  Xgboost, ensembled decision trees algorithms.
* **House Prices: Advanced Regression Techniques** - Regression model predicting the price of home based on the features and facilities. 

